"""
æµ‹è¯•LLMå›å¤ä¸ºç©ºçš„é—®é¢˜
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.llm_client import LLMClient
from src.game_state import GameState

def test_llm_responses():
    """æµ‹è¯•å„ç§LLMè°ƒç”¨æ˜¯å¦è¿”å›ç©ºå›å¤"""
    
    # æ£€æŸ¥é…ç½®
    import json
    try:
        with open("game_config.json", "r", encoding="utf-8") as f:
            config = json.load(f)
        api_key = config.get("api_key")
        base_url = config.get("base_url")
        model = config.get("model", "gpt-3.5-turbo")
    except:
        print("âŒ æ— æ³•è¯»å–é…ç½®æ–‡ä»¶ï¼Œè¯·ç¡®ä¿ game_config.json å­˜åœ¨")
        return
    
    if not api_key:
        print("âŒ API Key æœªé…ç½®")
        return
    
    print(f"ğŸ”‘ ä½¿ç”¨API Key: {api_key[:10]}...")
    print(f"ğŸŒ ä½¿ç”¨Base URL: {base_url}")
    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model}")
    print()
    
    # åˆ›å»ºLLMå®¢æˆ·ç«¯
    try:
        llm_client = LLMClient(api_key=api_key, base_url=base_url, model=model)
    except Exception as e:
        print(f"âŒ LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # åŠ è½½å‚è€ƒè¯„åˆ†è¡¨
    try:
        with open("prompt/ref_scoring_table.txt", "r", encoding="utf-8") as f:
            ref_table = f.read()
    except:
        print("âŒ æ— æ³•è¯»å–å‚è€ƒè¯„åˆ†è¡¨")
        return
    
    print("=== æµ‹è¯•åŸºç¡€LLMè°ƒç”¨ ===")
    try:
        basic_response = llm_client.call_llm("è¯·è¯´'ä½ å¥½'")
        print(f"åŸºç¡€è°ƒç”¨ç»“æœ: '{basic_response}'")
        print(f"ç»“æœé•¿åº¦: {len(basic_response)}")
        print(f"æ˜¯å¦ä¸ºç©º: {not basic_response.strip()}")
        print()
    except Exception as e:
        print(f"âŒ åŸºç¡€LLMè°ƒç”¨å¤±è´¥: {e}")
        return
    
    print("=== æµ‹è¯•äººç±»LLMè°ƒç”¨ ===")
    try:
        human_response = llm_client.call_human_llm(
            country_score=60,
            shoreline_score=100,
            opportunities="æµ·å²¸çº¿æä¾›ä¸°å¯Œçš„æ¸”ä¸šèµ„æºå’Œæ—…æ¸¸æ½œåŠ›",
            challenges="æµ·å²¸ä¾µèš€å’Œæµ·æ´‹æ±¡æŸ“å¨èƒç”Ÿæ€å¹³è¡¡",
            ref_table=ref_table
        )
        print(f"äººç±»LLMè°ƒç”¨ç»“æœ: {human_response}")
        print(f"action_1 æ˜¯å¦ä¸ºç©º: {not human_response.get('action_1', '').strip()}")
        print(f"action_2 æ˜¯å¦ä¸ºç©º: {not human_response.get('action_2', '').strip()}")
        print()
    except Exception as e:
        print(f"âŒ äººç±»LLMè°ƒç”¨å¤±è´¥: {e}")
        print()
    
    print("=== æµ‹è¯•æµ·å²¸çº¿LLMè°ƒç”¨ ===")
    try:
        shore_response = llm_client.call_shore_llm(
            "ACTION_1: å‘å±•å¯æŒç»­æ¸”ä¸š\nACTION_2: å»ºè®¾æµ·å²¸é˜²æŠ¤è®¾æ–½"
        )
        print(f"æµ·å²¸çº¿LLMè°ƒç”¨ç»“æœ: {shore_response}")
        print(f"opportunities æ˜¯å¦ä¸ºç©º: {not shore_response.get('opportunities', '').strip()}")
        print(f"challenges æ˜¯å¦ä¸ºç©º: {not shore_response.get('challenges', '').strip()}")
        print()
    except Exception as e:
        print(f"âŒ æµ·å²¸çº¿LLMè°ƒç”¨å¤±è´¥: {e}")
        print()
    
    print("=== æµ‹è¯•è£åˆ¤LLMè°ƒç”¨ ===")
    try:
        judge_response = llm_client.call_judge_llm(
            "ACTION_1: å‘å±•å¯æŒç»­æ¸”ä¸š\nACTION_2: å»ºè®¾æµ·å²¸é˜²æŠ¤è®¾æ–½",
            ref_table
        )
        print(f"è£åˆ¤LLMè°ƒç”¨ç»“æœ: {judge_response}")
        required_keys = ['first_country', 'first_shoreline', 'second_country', 'second_shoreline']
        for key in required_keys:
            print(f"{key}: {judge_response.get(key, 'missing')}")
        print()
    except Exception as e:
        print(f"âŒ è£åˆ¤LLMè°ƒç”¨å¤±è´¥: {e}")
        print()

if __name__ == "__main__":
    test_llm_responses()
